# ðŸŽ¬ ReelRecs: Movie Recommendation System

**ReelRecs** is a neural network-based movie recommendation system built for an online cinema platform. The system leverages a Deep Structured Semantic Model (DSSM) to learn user-item interactions and generate personalized film recommendations.

---

## ðŸš€ Project Structure

```
reelrecs/
â”œâ”€â”€ .gitignore               # General ignore rules
â”œâ”€â”€ data/.gitignore          # Placeholder for data files
â”œâ”€â”€ model_weights/.gitignore # Placeholder for model weights
â”œâ”€â”€ baseline.ipynb           # Baseline realisation and metrics of it
â”œâ”€â”€ EDA.ipynb                # Exploratory data analysis
â”œâ”€â”€ preprocessing.ipynb      # Data preprocessing steps
â”œâ”€â”€ train_dssm.ipynb         # DSSM model training pipeline
â”œâ”€â”€ early_stopping.py        # Custom early stopping callback
â”œâ”€â”€ metrics.py               # Metrics script 
â”œâ”€â”€ study_results.json       # Results of hyperparameter optimization
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md                # Project documentation
```

---

## ðŸ§  Approach

This project implements a **DSSM-based architecture** to embed users and movies into a shared latent space, enabling efficient retrieval of relevant content.

The training pipeline involves:

* Data preprocessing & filtering
* Feature engineering (user/movie embeddings)
* Training with early stopping
* Logging & evaluation

Hyperparameter tuning and experiment tracking were conducted using [Weights & Biases (wandb)](https://wandb.ai/).

> âš ï¸ The dataset and model weights are **not included** in this repository.

---

## ðŸ“¦ Setup

Ensure you're using **Python 3.10**.

Create and activate a virtual environment:

Using `venv`:

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

Or using [`uv`](https://github.com/astral-sh/uv):

```bash
uv venv -p 3.10
source .venv/bin/activate
uv install -r requirements.txt
```

---

## ðŸ“ Data

Place your data files inside the `data/` directory.
Example (for the KION dataset):

```
data/
â””â”€â”€ data_kion/
    â”œâ”€â”€ interactions.csv
    â””â”€â”€ metadata.csv
```

> Ensure the data format matches the expectations defined in `preprocessing.ipynb`.

---

## ðŸ“Š Notebooks

* **EDA.ipynb** â€” initial data analysis and visualizations
* **preprocessing.ipynb** â€” cleaning and transforming the dataset
* **train\_dssm.ipynb** â€” model training and evaluation

---

## ðŸ“Š Logging & Tracking with Weights & Biases (W&B)

During training, the model logs metrics and visualizations to [Weights & Biases](https://wandb.ai/):

- Training & validation loss
- Accuracy per epoch
- Confusion matrix & misclassification analysis

To enable logging, make sure you are logged in:

```bash
wandb login
```

By default, W&B is integrated in the training script:

```python
import wandb
wandb.init(project="whisper-emotion")
```

You can monitor training in real time at [wandb.ai](https://wandb.ai/) or in your terminal.

---

## ðŸ“« Contact

For questions or collaboration ideas, feel free to reach out via GitHub Issues.
